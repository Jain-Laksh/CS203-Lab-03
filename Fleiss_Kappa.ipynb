{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "jRZlRbRfGp-_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-WHvhOdPBwap"
      },
      "outputs": [],
      "source": [
        "# Load the JSON files\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Extract annotations from the JSON data\n",
        "def extract_annotations(data, is_soham=False):\n",
        "    annotations = {}\n",
        "    for item in data:\n",
        "        if is_soham: # For Soham's data, the image path is under the key \"image\" so we have handled this differently\n",
        "            image_id = item['image'].split('-')[-1].split('.')[0]  # Extract image ID (For example, 540 from \"e2495568-img_540.jpg\")\n",
        "            choice = item['choice']\n",
        "        else:\n",
        "            # For our data, the image path is under the key \"file_upload\"\n",
        "            image_id = item['file_upload'].split('-')[-1].split('.')[0]\n",
        "            choice = item['annotations'][0]['result'][0]['value']['choices'][0]\n",
        "        annotations[image_id] = choice\n",
        "    return annotations\n",
        "\n",
        "# Combine annotations from all annotators\n",
        "def combine_annotations(annotators_data):\n",
        "    combined = {}\n",
        "    for annotator, data in annotators_data.items():\n",
        "        for image_id, choice in data.items():\n",
        "            if image_id not in combined:\n",
        "                combined[image_id] = {'Trucks': 0, 'No Trucks': 0}\n",
        "            combined[image_id][choice] += 1\n",
        "    return combined\n",
        "\n",
        "def fleiss_kappa(combined_annotations, num_annotators):\n",
        "    N = len(combined_annotations)  # Number of images\n",
        "    k = 2  # Number of categories: \"Trucks\" and \"No Trucks\"\n",
        "\n",
        "    # P_a (observed agreement)\n",
        "    total_agreement = 0\n",
        "    for counts in combined_annotations.values():\n",
        "        total_agreement += sum(count * (count - 1) for count in counts.values())\n",
        "    P_a = total_agreement / (N * num_annotators * (num_annotators - 1))\n",
        "\n",
        "    # P_e (expected agreement by chance)\n",
        "    category_totals = {}\n",
        "    for counts in combined_annotations.values():\n",
        "        for category, count in counts.items():\n",
        "            if category not in category_totals:\n",
        "                category_totals[category] = 0\n",
        "            category_totals[category] += count\n",
        "    total_assignments = sum(category_totals.values())\n",
        "    P_e = sum((category_total / total_assignments) ** 2 for category_total in category_totals.values())\n",
        "\n",
        "    # Calculate Fleiss' Kappa\n",
        "    kappa = (P_a - P_e) / (1 - P_e)\n",
        "    return kappa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "laksh_data = load_json('CV_laksh.json')\n",
        "soham_data = load_json('CV_soham.json')\n",
        "tanish_data = load_json('CV_tanish.json')\n",
        "\n",
        "laksh_annotations = extract_annotations(laksh_data)\n",
        "soham_annotations = extract_annotations(soham_data, is_soham=True)  # Handle Soham's data differently\n",
        "tanish_annotations = extract_annotations(tanish_data)\n",
        "\n",
        "print(laksh_annotations)\n",
        "print(soham_annotations)\n",
        "print(tanish_annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDzpgxtSDoJc",
        "outputId": "f9954bd3-16f6-4c0b-b8c1-5cd179ea505e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'img_540': 'Trucks', 'img_541': 'Trucks', 'img_543': 'No Trucks', 'img_544': 'No Trucks', 'img_545': 'No Trucks', 'img_546': 'Trucks', 'img_547': 'Trucks', 'img_548': 'No Trucks', 'img_549': 'Trucks', 'img_550': 'No Trucks', 'img_551': 'Trucks', 'img_553': 'Trucks', 'img_554': 'No Trucks', 'img_555': 'No Trucks', 'img_556': 'No Trucks', 'img_557': 'No Trucks', 'img_558': 'No Trucks', 'img_559': 'No Trucks'}\n",
            "{'img_540': 'Trucks', 'img_541': 'No Trucks', 'img_543': 'No Trucks', 'img_544': 'No Trucks', 'img_545': 'No Trucks', 'img_546': 'No Trucks', 'img_547': 'Trucks', 'img_548': 'No Trucks', 'img_549': 'Trucks', 'img_550': 'No Trucks', 'img_551': 'No Trucks', 'img_553': 'Trucks', 'img_554': 'No Trucks', 'img_555': 'No Trucks', 'img_556': 'No Trucks', 'img_557': 'No Trucks', 'img_558': 'No Trucks', 'img_559': 'Trucks'}\n",
            "{'img_540': 'Trucks', 'img_541': 'Trucks', 'img_543': 'No Trucks', 'img_544': 'No Trucks', 'img_545': 'No Trucks', 'img_546': 'Trucks', 'img_547': 'Trucks', 'img_548': 'No Trucks', 'img_549': 'Trucks', 'img_550': 'No Trucks', 'img_551': 'No Trucks', 'img_553': 'Trucks', 'img_554': 'Trucks', 'img_555': 'No Trucks', 'img_556': 'Trucks', 'img_557': 'No Trucks', 'img_558': 'No Trucks', 'img_559': 'Trucks'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine annotations\n",
        "annotators_data = {\n",
        "    'Laksh': laksh_annotations,\n",
        "    'Soham': soham_annotations,\n",
        "    'Tanish': tanish_annotations\n",
        "}\n",
        "combined_annotations = combine_annotations(annotators_data)\n",
        "\n",
        "# Calculating Fleiss' Kappa\n",
        "num_annotators = 3\n",
        "kappa = fleiss_kappa(combined_annotations, num_annotators)\n",
        "\n",
        "print(f\"Fleiss' Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkKStblQEV-G",
        "outputId": "8c3b6fec-25fa-4749-b3bd-a03bd0e2a24e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fleiss' Kappa: 0.5325\n"
          ]
        }
      ]
    }
  ]
}